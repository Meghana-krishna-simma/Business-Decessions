{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meghana-krishna-simma/Business-Decessions/blob/main/Copy_of_Breast_Cancer_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F596543%2F1073067%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240320%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240320T190821Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4e13313de7c33a850fea601c7a5f989456e36c27f8f4ef46117d850f36a62df02cde7cfb1aaca7f817b7d1f6527b59be12fba4e188431f83b3f2018593b60f6189994efabc750483b0f5b47c64de48578ce7eeab112105cf68b3fd8ab9ec623412b0cda3efdc7c6a15f9d3d952a0ce4e4bbd955712f6dabe83f1d883e0c0ef07e2700d4e6c184d2a750860f1a00aa01cd2d229534512d838e0517ce0dd26175a83762c2d11ed8b1278e19505bff4d3d498fcbb8cff7d1b538c7df912a11693a1fc8f2d6bf604829856955d3321498a4ef747003fa24631ba99e2715643127c83fb8e46338c344126e92618819532c64e8327c225ca77956996a651752468bf96'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "jqQzMCE7Q8CW"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "zVbuhJJTQ8Ca"
      },
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "\n",
        "Breast Cancer is one of the leading cancer developed in many countries including India.With early diagnosis 97% women can survive for more than 5 years. Statistically, the death toll due to this disease has increased drastically in last few decades. If we recognise early, we can take the necesaary action which results in less death toll. Hence,apart from medicinal solutions some Data Science solution needs to be integrated for resolving the death causing issue."
      ]
    },
    {
      "metadata": {
        "id": "pG3kdfwvQ8Cc"
      },
      "cell_type": "markdown",
      "source": [
        "# Objective:\n",
        "To Build a breast cancer classifier on the dataset that can be accurately classify as benign and malignant."
      ]
    },
    {
      "metadata": {
        "id": "FqoXIrPnQ8Cd"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing the Packages"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Xv04l7vXQ8Cd"
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ABYno3PPQ8Ce"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aFbcu_GuQ8Ce"
      },
      "cell_type": "code",
      "source": [
        "cell_df=pd.read_csv(\"/kaggle/input/cell_samples.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntS6YfnIQ8Cf"
      },
      "cell_type": "markdown",
      "source": [
        "# About the dataset.\n",
        "\n",
        "When pathologists examine FNA(fine needle aspirate) tissues samples in breast cancer diagnosis,they consider the nine attributes.each of the attribute is assigned to number from 1-10 by the pathologists.the larger the number the\n",
        "greater the likelihood of malignancy.no single measurement can be used to determine whether it is benign or malignant."
      ]
    },
    {
      "metadata": {
        "id": "2QxFjE8yQ8Cf"
      },
      "cell_type": "markdown",
      "source": [
        "This is the description of the features of the dataset.\n",
        "\n",
        "1. Sample code number: id number\n",
        "2. Clump Thickness: 1 - 10\n",
        "3. Uniformity of Cell Size: 1 - 10\n",
        "4. Uniformity of Cell Shape: 1 - 10\n",
        "5. Marginal Adhesion: 1 - 10\n",
        "6. Single Epithelial Cell Size: 1 - 10\n",
        "7. Bare Nuclei: 1 - 10\n",
        "8. Bland Chromatin: 1 - 10\n",
        "9. Normal Nucleoli: 1 - 10\n",
        "10. Mitoses: 1 - 10\n",
        "11. Class: (2 for benign, 4 for malignant)"
      ]
    },
    {
      "metadata": {
        "id": "r_IuOd6uQ8Cg"
      },
      "cell_type": "markdown",
      "source": [
        "Clump thickness indicates that radius was computed by averaging the length of radial line segments from the center of\n",
        "the nuclear mass to each of the points of the nuclear border. For cell size, perimeter was measured as the distance\n",
        "around the nuclear border which is considered to be uniform. For measuring the cell shape, area is measured by\n",
        "counting the number of pixels in the interior of the nuclear border and adding one-half of the pixels on the perimeter.\n",
        "Marginal adhesion is measured bycombining the perimeter and area to give a measure of the compactness of the cell\n",
        "nuclei"
      ]
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": false,
        "id": "e2pQabsSQ8Cg"
      },
      "cell_type": "markdown",
      "source": [
        "#classify cells to whether the samples are benign(mild state)=2 or malignant(evil state)=4"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "MvszhRJIQ8Cg"
      },
      "cell_type": "code",
      "source": [
        "# There are 699 records and for each record we have multiple parameters that is measured.\n",
        "# Public Source - https://s3-api.us-geo.objectstorage.s... \"\n",
        "# we are using a dataset that has a 9 predictors in each record, 699 records"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aQKvumfoQ8Ch"
      },
      "cell_type": "code",
      "source": [
        "cell_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yo9nHO8YQ8Ch"
      },
      "cell_type": "code",
      "source": [
        "cell_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ytuQUgJqQ8Ch"
      },
      "cell_type": "markdown",
      "source": [
        "* ‘id’, ‘clump thickness’, ‘uniformity of cell size’, ‘uniformity of cell shape’, ‘marginal adhesion’, ‘single epithelial cell size’, ‘bare nuclei’, ‘bland chromatin’, ‘normal nucleoli’, ‘mitosis’ are the variables used to predict the output ‘class’."
      ]
    },
    {
      "metadata": {
        "id": "gqkPsztmQ8Ci"
      },
      "cell_type": "markdown",
      "source": [
        "# Dropping the unwanted columns."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8b0YP24NQ8Ci"
      },
      "cell_type": "code",
      "source": [
        "# Let us drop the ID column as it doesnot influence the output \"class\".\n",
        "cell_df.drop('ID',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "6ZjoEnauQ8Ci"
      },
      "cell_type": "code",
      "source": [
        "cell_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efBlMuI7Q8Cj"
      },
      "cell_type": "markdown",
      "source": [
        "The data frame is of shape (699,10) suggesting there are 699 training cases."
      ]
    },
    {
      "metadata": {
        "id": "jRvhLEGpQ8Cj"
      },
      "cell_type": "markdown",
      "source": [
        "# Checking for missing values"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uUK85MEOQ8Cj"
      },
      "cell_type": "code",
      "source": [
        "#Missing Or Null data points\n",
        "\n",
        "cell_df.isnull().sum()\n",
        "cell_df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnYs2AcWQ8Cj"
      },
      "cell_type": "markdown",
      "source": [
        "No Missing values found in the dataset."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "AQK4KtdzQ8Cj"
      },
      "cell_type": "code",
      "source": [
        "cell_df.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZ-Dqhc0Q8Cj"
      },
      "cell_type": "markdown",
      "source": [
        "The count of each column is 699 which suggests there are no missing values."
      ]
    },
    {
      "metadata": {
        "id": "sOM5NEvLQ8Ck"
      },
      "cell_type": "markdown",
      "source": [
        "# Checking for Categorical variables"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JxEJdXcsQ8Ck"
      },
      "cell_type": "code",
      "source": [
        "cell_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uocE2ZcQQ8Ck"
      },
      "cell_type": "code",
      "source": [
        "col_names = ['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit', 'Class']\n",
        "for x in col_names:\n",
        "    print(cell_df[x].nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a9WJq-U-Q8Ck"
      },
      "cell_type": "markdown",
      "source": [
        "All the variables are Categorical variables."
      ]
    },
    {
      "metadata": {
        "id": "qlxVDRhMQ8Ck"
      },
      "cell_type": "markdown",
      "source": [
        "# Checking whether the dataset is a balanced or not."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8SYXY3UyQ8Ck"
      },
      "cell_type": "code",
      "source": [
        "# Let us check whether the dataset is a balanced or imbalanced one.\n",
        "target_count = cell_df.Class.value_counts()\n",
        "print('Benign:', target_count[2])\n",
        "print('Malignant:', target_count[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "DJ6OH5-MQ8Ck"
      },
      "cell_type": "code",
      "source": [
        "458/241"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qPWfUw77Q8Cl"
      },
      "cell_type": "markdown",
      "source": [
        "It is a balanced dataset. the proportion of benign and malignant is almost 2:1."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "F8JSn0JZQ8Cl"
      },
      "cell_type": "code",
      "source": [
        "cell_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oZ5mPzhcQ8Cl"
      },
      "cell_type": "markdown",
      "source": [
        "BareNuc variable is an object data type, so need to convert it into integer data type."
      ]
    },
    {
      "metadata": {
        "id": "oS_bI6GrQ8Cl"
      },
      "cell_type": "markdown",
      "source": [
        "Bare Buc is an object type which is not a numeric value. So, we cannot apply mathematical operations on this column.\n",
        "So, Here lets simply removethe non numeric data.\n",
        "For a particular row, and in that row a particular column( BareNuc) if values are non numeric. We could simply remove it, as synthetic data would not contribute to right decisions."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "qWRTApxzQ8Cl"
      },
      "cell_type": "code",
      "source": [
        "# Identify the unwanted rows\n",
        "\n",
        "cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'],errors='coerce').notnull()]\n",
        "cell_df['BareNuc']=cell_df['BareNuc'].astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "gBMfsCNoQ8Cm"
      },
      "cell_type": "code",
      "source": [
        "cell_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1GYjM5REQ8Cm"
      },
      "cell_type": "markdown",
      "source": [
        "So, BareNuc  is converted to integer data type."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Mr0YbO8MQ8Cm"
      },
      "cell_type": "code",
      "source": [
        "cell_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UaqsvaHQ8Cq"
      },
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ART7UytAQ8Cr"
      },
      "cell_type": "code",
      "source": [
        "cell_df.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j8QSiPH1Q8Cr"
      },
      "cell_type": "markdown",
      "source": [
        "The output variable ‘class’ is discrete and takes two values :- 2 (Benign) and 4 (Malignant).\n",
        "The mean of ‘class’ is closer to 2 indicating there are more benign cases.\n",
        "The minimum and maximum value of all input variables are 1 and 10 respectively."
      ]
    },
    {
      "metadata": {
        "id": "i4bZvBR6Q8Cr"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Visualisation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YbcE8Fy4Q8Cr"
      },
      "cell_type": "code",
      "source": [
        "cell_df.hist(figsize=(20,12))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0V9jUPOWQ8Cr"
      },
      "cell_type": "markdown",
      "source": [
        "‘clump thickness’ is evenly distributed to some extent. All other variables are skewed to the right."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RkywBQo9Q8Cr"
      },
      "cell_type": "code",
      "source": [
        "cell_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rS2eEJmzQ8Cr"
      },
      "cell_type": "markdown",
      "source": [
        "# Taking out the predictors and predicted variables seperately"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CrEHzqYZQ8Cr"
      },
      "cell_type": "code",
      "source": [
        "# Taking out the predictors and predicted variables seperately for the further.\n",
        "\n",
        "feature_df=cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize',\n",
        "       'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\n",
        "x=np.asarray(feature_df)\n",
        "y=np.asarray(cell_df['Class'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Wvj3Y5_-Q8Cs"
      },
      "cell_type": "code",
      "source": [
        "x[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iOwiwbqyQ8Cs"
      },
      "cell_type": "markdown",
      "source": [
        "# Splitting the dataset."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "jh2ItGxAQ8Cs"
      },
      "cell_type": "code",
      "source": [
        "# Divide the data as train and test dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=4)\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AuIy0OtXQ8Cs"
      },
      "cell_type": "markdown",
      "source": [
        "# Training My Models"
      ]
    },
    {
      "metadata": {
        "id": "aavIprtxQ8Cs"
      },
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RofEsjtJQ8Ct"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr=LogisticRegression(C=100,random_state=0)\n",
        "lr.fit(x_train,y_train)\n",
        "y_pred=lr.predict(x_test)\n",
        "correct = (y_test == y_pred).sum()\n",
        "incorrect = (y_test != y_pred).sum()\n",
        "accuracy = correct / (correct + incorrect) * 100\n",
        "\n",
        "print('\\nPercent Accuracy: %0.1f' %accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "EPQDWiWkQ8Ct"
      },
      "cell_type": "code",
      "source": [
        "prediction = pd.DataFrame()\n",
        "prediction['actual'] = y_test\n",
        "prediction['predicted'] = y_pred\n",
        "prediction['correct'] = prediction['actual'] == prediction['predicted']\n",
        "\n",
        "print ('\\nDetailed results for first 20 tests:')\n",
        "print (prediction.head(20))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_lHc2CJ9Q8Ct"
      },
      "cell_type": "code",
      "source": [
        "#Accuracy of our model.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c_logistic=confusion_matrix(y_test,y_pred)\n",
        "print(c_logistic)\n",
        "Accuracy_logistic=sum(np.diag(c_logistic))/(np.sum(c_logistic))\n",
        "Accuracy_logistic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "EU426t9BQ8Ct"
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BI-RZvQSQ8Ct"
      },
      "cell_type": "markdown",
      "source": [
        "The metrics for this model are as follows\n",
        "Accuracy : 97.08 %,\n",
        "Precision : 96%,\n",
        "Recall: 98%,\n",
        "F1 Score: 97%."
      ]
    },
    {
      "metadata": {
        "id": "t0ikSIM9Q8Cu"
      },
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ozuysyvRQ8Cu"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier_naive=GaussianNB()\n",
        "classifier_naive.fit(x_train, y_train)\n",
        "y_predict=classifier_naive.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7ks8e66gQ8Cu"
      },
      "cell_type": "code",
      "source": [
        "#Accuracy of our model.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c_naive=confusion_matrix(y_test,y_predict)\n",
        "print(c_naive)\n",
        "Accuracy_naive=sum(np.diag(c_naive))/(np.sum(c_naive))\n",
        "Accuracy_naive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ahEY5s_AQ8Cu"
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Plmq8onQ8Cu"
      },
      "cell_type": "markdown",
      "source": [
        "The metrics for this model are as follows\n",
        "Accuracy : 94.89 %,\n",
        "Precision : 94%,\n",
        "Recall: 96%,\n",
        "F1 Score: 95%."
      ]
    },
    {
      "metadata": {
        "id": "LbIejM6cQ8Cv"
      },
      "cell_type": "markdown",
      "source": [
        "# SVM Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-l74K5v3Q8Cv"
      },
      "cell_type": "code",
      "source": [
        "#modelling SVM\n",
        "\n",
        "from sklearn import svm\n",
        "classifier_svm=svm.SVC(kernel='linear',gamma='auto',C=1)\n",
        "classifier_svm.fit(x_train,y_train)\n",
        "y_predict=classifier_svm.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "g0kJX_L6Q8Cv"
      },
      "cell_type": "code",
      "source": [
        "# Confusion matrix and Accuracy of our model.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c_svm=confusion_matrix(y_test,y_predict)\n",
        "print(c_svm)\n",
        "Accuracy_svm=sum(np.diag(c_svm))/(np.sum(c_svm))\n",
        "Accuracy_svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-iULTlBRE1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "tE-Kq_BrQ8Cv"
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPT1LRxMQ8Cv"
      },
      "cell_type": "markdown",
      "source": [
        "The metrics for this model are as follows\n",
        "Accuracy : 96.35 %,\n",
        "Precision : 95%,\n",
        "Recall: 97%,\n",
        "F1 Score: 96%.\n"
      ]
    },
    {
      "metadata": {
        "id": "LYZWurCpQ8Cw"
      },
      "cell_type": "markdown",
      "source": [
        "# Kernal SVM. Kernal taken is polynomial kernal."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Jr3xtzoRQ8Cw"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "classifier_svmk=svm.SVC(kernel='poly',gamma='auto',C=1)\n",
        "classifier_svmk.fit(x_train,y_train)\n",
        "y_predict=classifier_svmk.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "kX8OQUMxQ8Cw"
      },
      "cell_type": "code",
      "source": [
        "#Accuracy of our model.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c_svmk=confusion_matrix(y_test,y_predict)\n",
        "print(c_svmk)\n",
        "Accuracy_svmk=sum(np.diag(c_svmk))/(np.sum(c_svmk))\n",
        "Accuracy_svmk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4U_bjVACQ8Cw"
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9_t2mk00Q8Cx"
      },
      "cell_type": "markdown",
      "source": [
        "The metrics for this model are as follows\n",
        "Accuracy : 97.08 %,\n",
        "Precision : 96%,\n",
        "Recall: 98%,\n",
        "F1 Score: 97%."
      ]
    },
    {
      "metadata": {
        "id": "C64ZjTzVQ8Cx"
      },
      "cell_type": "markdown",
      "source": [
        "# KNN Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ER-phHjHQ8Cx"
      },
      "cell_type": "code",
      "source": [
        "# modelling Knn Classifier\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# nothing but we are using euclidean distance\n",
        "classifier_knn=KNeighborsClassifier(n_neighbors=6,metric=\"minkowski\",p=2)\n",
        "classifier_knn.fit(x_train,y_train)\n",
        "y_predict=classifier_knn.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aPlJ0o4XQ8Cx"
      },
      "cell_type": "markdown",
      "source": [
        "Let us find the optimum value for K. Here we have taken the loop iteration till 27 as per thumb rule optimum k value is always Square root of number of records. so square root of 699 rounds of to 26. So that is why it is taken."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uBP-MtxuQ8Cx"
      },
      "cell_type": "code",
      "source": [
        "# lets see the best value of k for which the model is predicting with high accuracy.\n",
        "\n",
        "n=[]\n",
        "acc=[]\n",
        "\n",
        "for i in range(1,27):\n",
        "    classifier_knn_trail=KNeighborsClassifier(n_neighbors=i,metric=\"minkowski\",p=2)\n",
        "    classifier_knn_trail.fit(x_train,y_train)\n",
        "    c_knn_trail=confusion_matrix(y_test,classifier_knn_trail.predict(x_test))\n",
        "    acc.append(sum(np.diag(c_knn_trail))/(np.sum(c_knn_trail)))\n",
        "    n.append(i)\n",
        "n=np.array(n)\n",
        "acc=np.array(acc)\n",
        "plt.plot(n,acc)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "E8TXb9UFQ8Cx"
      },
      "cell_type": "code",
      "source": [
        "#Accuracy of our model.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c_knn=confusion_matrix(y_test,y_predict)\n",
        "print(c_knn)\n",
        "Accuracy_knn=sum(np.diag(c_knn))/(np.sum(c_knn))\n",
        "Accuracy_knn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vSkWiRWTQ8Cx"
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0hqws5xqQ8Cy"
      },
      "cell_type": "markdown",
      "source": [
        "The metrics for this model are as follows\n",
        "Accuracy : 98.54 %,\n",
        "Precision : 98%,\n",
        "Recall: 99%,\n",
        "F1 Score: 98%."
      ]
    },
    {
      "metadata": {
        "id": "-F6eFPtuQ8Cy"
      },
      "cell_type": "markdown",
      "source": [
        "# Decision tree"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fUaX589EQ8Cy"
      },
      "cell_type": "code",
      "source": [
        "# Fitting Decision Tree Classification to the Training set\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier_tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)# for gini 0.948905109489051\n",
        "classifier_tree.fit(x_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_predict = classifier_tree.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "qaOaUjH8Q8Cy"
      },
      "cell_type": "code",
      "source": [
        "#Accuracy of our model.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c_tree=confusion_matrix(y_test,y_predict)\n",
        "print(c_tree)\n",
        "Accuracy_tree=sum(np.diag(c_tree))/(np.sum(c_tree))\n",
        "Accuracy_tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Fr0maT6hQ8Cy"
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v33jM4kPQ8Cy"
      },
      "cell_type": "markdown",
      "source": [
        "The metrics for this model are as follows\n",
        "Accuracy : 96.35 %,\n",
        "Precision : 96%,\n",
        "Recall: 96%,\n",
        "F1 Score: 96%."
      ]
    },
    {
      "metadata": {
        "id": "75KXwvdmQ8Cz"
      },
      "cell_type": "markdown",
      "source": [
        "# Random forest"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YSeiCXGGQ8Cz"
      },
      "cell_type": "code",
      "source": [
        "# Fitting Random Forest Classification to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier_ensemble = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
        "classifier_ensemble.fit(x_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_predict = classifier_ensemble.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aGyi50DEQ8Cz"
      },
      "cell_type": "code",
      "source": [
        "#Accuracy of our model.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c_ensemble=confusion_matrix(y_test,y_predict)\n",
        "print(c_ensemble)\n",
        "Accuracy_ensemble=sum(np.diag(c_ensemble))/(np.sum(c_ensemble))\n",
        "Accuracy_ensemble"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GLnaeH1jQ8Cz"
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zl7cAmCOQ8Cz"
      },
      "cell_type": "markdown",
      "source": [
        "The metrics for this model are as follows\n",
        "Accuracy : 97.81 %,\n",
        "Precision : 97%,\n",
        "Recall: 98%,\n",
        "F1 Score: 98%."
      ]
    },
    {
      "metadata": {
        "id": "yTFSIGHxQ8Cz"
      },
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GLnXDo5xQ8Cz"
      },
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OKGYofAAQ8Cz"
      },
      "cell_type": "code",
      "source": [
        "# Fitting the XGBoost to the training set\n",
        "from xgboost import XGBClassifier\n",
        "classifier_xg=XGBClassifier()\n",
        "classifier_xg.fit(x_train,y_train)\n",
        "\n",
        "# Predicting the test results\n",
        "y_predictor= classifier_xg.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zFSQSU8kQ8Cz"
      },
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "#Accuracy of our model.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c_xg=confusion_matrix(y_test,y_predictor)\n",
        "print(c_xg)\n",
        "Accuracy_xg=sum(np.diag(c_xg))/(np.sum(c_xg))\n",
        "Accuracy_xg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1qguAUdiQ8C0"
      },
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_predictor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EOidaemcQ8C1"
      },
      "cell_type": "markdown",
      "source": [
        "The metrics for this model are as follows\n",
        "Accuracy : 97.81 %,\n",
        "Precision : 97%,\n",
        "Recall: 98%,\n",
        "F1 Score: 98%."
      ]
    },
    {
      "metadata": {
        "id": "QKcjo9XpQ8C2"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation Metrics"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "sYKA6iX5Q8C2"
      },
      "cell_type": "code",
      "source": [
        "d={'Accuracy(%)' : [97.08,94.89,96.35,97.08,98.54,96.35,97.81,97.91],'Precision' : [0.96,0.94,0.95,0.96,0.98,0.96,0.97,0.97],'recall' : [0.98,0.96,0.97,0.98,0.99,0.96,0.98,0.98],'F1 Score' : [0.97,0.95,0.96,0.97,0.98,0.96,0.98,0.98]}\n",
        "Model_metrics = pd.DataFrame(d,index=['Logistic Regression','Naive Bayes','Svm-Linear','Svm-Polynomial','KNN','Decison Tree','Random Forest','XGBoost'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3B-9tN0YQ8C2"
      },
      "cell_type": "code",
      "source": [
        "Model_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l25sRWoYQ8C2"
      },
      "cell_type": "markdown",
      "source": [
        "We can see KNN performing well and then comes random forest and XGBoost which have more accuracy and F1 Score as well."
      ]
    },
    {
      "metadata": {
        "id": "9z56NRgLQ8C2"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction using trained model\n",
        "The trained models is used to predict a particular case :- ‘clump thickness’ = 1, ‘uniformity of cell size’ = 2, ‘uniformity of cell shape’ = 2, ‘marginal adhesion’ = 5 , ‘single epithelial cell size’ = 3 , 'bare nuclei' = 4 , ‘bland chromatin’ = 6, ‘normal nucleoli’ = 4, ‘mitosis’ = 8."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "XgKMDBIvQ8C2"
      },
      "cell_type": "code",
      "source": [
        "y_predict=classifier_knn.predict(np.array([[1,2,2,5,3,4,6,4,8]]))\n",
        "print(y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZ8PamexQ8C2"
      },
      "cell_type": "markdown",
      "source": [
        "The predicted value of ‘class’ is 2 which suggests it is a benign tumor."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Pg1zKSY_Q8C2"
      },
      "cell_type": "code",
      "source": [
        "y_predict=classifier_ensemble.predict(np.array([[1,2,2,5,3,4,6,4,8]]))\n",
        "print(y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vadXMlc7Q8C3"
      },
      "cell_type": "markdown",
      "source": [
        "My random forest model is also predicting the same as benign."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Jh7Vb4JXQ8C3"
      },
      "cell_type": "code",
      "source": [
        "y_predict=classifier_xg.predict(np.array([[1,2,2,5,3,4,6,4,8]]))\n",
        "print(y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zEotVNCDQ8C3"
      },
      "cell_type": "markdown",
      "source": [
        "My xg boost model is also predicting the same as benign."
      ]
    },
    {
      "metadata": {
        "id": "sMuRvb6xQ8C3"
      },
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "Breast Cancer has become the foremost cause of death worldwide for womens. The most successful way to reduce\n",
        "cancer deaths is to detect it earlier. Many people avoid cancer screening due to the cost involved in taking numerous\n",
        "tests for diagnosis.This prediction system may provide easy and a cost effective way for screening cancer and may play\n",
        "a significant role in earlier diagnosis process for different types of cancer and provide effective preventive\n",
        "approach."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}